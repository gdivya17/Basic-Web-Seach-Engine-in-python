{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://calnewport.com/blog/', 'https://www.helpscout.net/blog/', 'https://www.helpscout.net/blog/', 'https://www.helpscout.net/blog/']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "import re\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "#function for normalizing the text data    \n",
    "#input: string; output: string\n",
    "def processed(phrase):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    phrase=phrase.lower()\n",
    "    phrase = re.sub('[^A-Za-z0-9]+', '  ', phrase)\n",
    "    word_tokens = word_tokenize(phrase)\n",
    "    filtered_sentence = [lemmatizer.lemmatize(w, pos='v') for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = [lemmatizer.lemmatize(w, pos='a') for w in filtered_sentence]\n",
    "    filtered_sentence = [lemmatizer.lemmatize(w, pos='n') for w in filtered_sentence]\n",
    "    phrase=' '.join(filtered_sentence)\n",
    "    phrase = re.sub('[0-9]+', '', phrase)\n",
    "    return phrase\n",
    "\n",
    "#function for downloading each web page and removing tags in the resulting HTML)\n",
    "#input: list (of url); output: list (of processed data from all the webpages for vectorization)\n",
    "def index_function(list_of_urls):\n",
    "    raw_data=[]\n",
    "    for url in list_of_urls:\n",
    "        raw = get(url) \n",
    "        raw_data.append(raw.content)\n",
    "    content=[]  \n",
    "    for i in raw_data:\n",
    "        con=[]\n",
    "        soup = BeautifulSoup(i, 'html.parser')\n",
    "        for j in soup.find_all(['a','p','title','div']):\n",
    "            con.append(j.get_text())\n",
    "        content.append(con)\n",
    "    del(con)\n",
    "    processed_data=[]\n",
    "    for i in content:\n",
    "        s=''\n",
    "        for j in i:\n",
    "            s=s+str(processed(j))\n",
    "        processed_data.append(s)\n",
    "    return(processed_data)\n",
    "\n",
    "#function BOW representation and ccalculating cosine distance of the the query and document of processed data\n",
    "#input: string (query); #output: list (ranked list)\n",
    "def search_function(query):\n",
    "    query=processed(query)\n",
    "    count_vect = CountVectorizer()\n",
    "    sparse_matrix1=count_vect.fit_transform(processed_data)\n",
    "    sparse_matrix2=count_vect.transform([query])\n",
    "    re=list(cosine_similarity(sparse_matrix1,sparse_matrix2))\n",
    "    res=[]\n",
    "    while(len(re)!=0):\n",
    "        res.append(a2[re.index(max(re))])\n",
    "        re.remove(max(re))\n",
    "    print(res)\n",
    "    \n",
    "    \n",
    "a2=['https://www.helpscout.net/blog/','https://1stwebdesigner.com/','http://whatiwore.tumblr.com/','http://calnewport.com/blog/'] \n",
    "#to load the list from text file:\n",
    "#import os\n",
    "#os.chdir(r'C:\\Users\\lenovo\\Desktop')\n",
    "#f=open(r'a.txt','r')\n",
    "#a1=f.read()\n",
    "#a2=a1.split('\\n')\n",
    "#f.close() \n",
    "processed_data=index_function(a2)\n",
    "search_function('book novel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
